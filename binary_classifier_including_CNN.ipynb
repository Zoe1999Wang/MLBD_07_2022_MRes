{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ace8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xlrd\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import laserbeamsize as lbs\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import stats~\n",
    "from PIL import Image\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def create_dataset(datapath):\n",
    "\n",
    "\n",
    "    img_data_array=[]\n",
    "    image_list0 = glob.glob(datapath)\n",
    "    image_list0=image_list0[15000:]\n",
    "#there are 20000 images in file, however due to the limited memory, only 5000 are used to create the dataset    \n",
    "              \n",
    "    a = np.zeros((len(image_list0),600,600))\n",
    "    for i in range (len(image_list0)):\n",
    "\n",
    "        img=cv2.imread(image_list0[i])\n",
    "        image_array = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        image_array=np.array(image_array)\n",
    "        a[i,:,:] = image_array\n",
    "    img_data_array=a\n",
    "    return img_data_array\n",
    "\n",
    "def create_scoreset(datapath,scorepath):\n",
    "    \n",
    "    def read_score(scorepath):\n",
    "\n",
    "        file = open(scorepath)\n",
    "        csvreader = csv.reader(file)\n",
    "        rows = []\n",
    "        for row in csvreader:\n",
    "                rows.append(row)\n",
    "        return rows\n",
    "\n",
    "    class_name=[]\n",
    "    image_list0 = glob.glob(datapath)\n",
    "    \n",
    "    def gaussian(x, amplitude, mean, stddev):\n",
    "        return amplitude * np.exp(-((x - mean) / 4 / stddev)**2)\n",
    "\n",
    "    def get_number_gaussuam(image_list):\n",
    "\n",
    "        Score_1=[]\n",
    "\n",
    "        for i in range (len(image_list)):\n",
    "\n",
    "            img=cv2.imread(image_list[i])\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            beam=gray\n",
    "            cx, cy, dx, dy, phi = lbs.beam_size(beam)\n",
    "            image_array = beam\n",
    "            x=np.linspace(0,600,600)\n",
    "\n",
    "            a=int(cx)\n",
    "            b=int(cy)\n",
    "            c=5 #box half-thickness\n",
    "            y_x=0\n",
    "\n",
    "            for j in range (a-c,a+c):\n",
    "                y_x=y_x+image_array[j,:]/100 #tricky here since if this number is >255 it becomes 0.\n",
    "            y_x=(y_x)/c*100\n",
    "\n",
    "            y_y=0\n",
    "\n",
    "            for j in range (b-c,b+c):\n",
    "                y_y=y_y+image_array[:,j]/100\n",
    "            y_y=((y_y)/c)*100\n",
    "\n",
    "\n",
    "            popt_x, pcov_x = optimize.curve_fit(gaussian, x, y_x+1,maxfev=500000) # tricky here!!!!! y_x+1\n",
    "            fitted_y_x=popt_x[0] * np.exp(-((x - popt_x[1]) / 4 / popt_x[2])**2)\n",
    "            a_x=r2_score(y_x,fitted_y_x)\n",
    "            popt_y, pcov_y = optimize.curve_fit(gaussian, x, y_y+1,maxfev=500000) # same here!!!! y_y+1\n",
    "            fitted_y_y=popt_y[0] * np.exp(-((x - popt_y[1]) / 4 / popt_y[2])**2)\n",
    "            a_y=r2_score(y_y,fitted_y_y)\n",
    "\n",
    "            s1=abs(a_x*a_y)\n",
    "            Score_1.append(s1)  \n",
    "\n",
    "        return Score_1 \n",
    "    #here use Gaussain fit to give score, other quality analysis method can be replaced here. see quality_number_analysis file.\n",
    "    s0=get_number_gaussuam(image_list0)  \n",
    "    outfile = open(scorepath,'w')\n",
    "    out = csv.writer(outfile)\n",
    "    out.writerows(map(lambda x: [x], s0))\n",
    "    outfile.close()\n",
    "    \n",
    "    def good_or_bad(scorepath):\n",
    "        strs = []\n",
    "        for i in range (len(read_score(scorepath))):\n",
    "            if read_score(scorepath)[i]>=['0.9']:\n",
    "                x=1 #good\n",
    "            else:\n",
    "                x=0 #bad\n",
    "                \n",
    "            strs.append(x)\n",
    "\n",
    "        return strs\n",
    "\n",
    "    class_name=good_or_bad(scorepath)\n",
    "    class_name = np.array(class_name)\n",
    "    \n",
    "    return class_name\n",
    "# extract the image array and class name\n",
    "X=create_dataset(r'/home/zw3721/Downloads/2022_master_project/M7/*.png')\n",
    "y=create_scoreset(r'/home/zw3721/Downloads/2022_master_project/M7/*.png','/home/zw3721/Downloads/2022_master_project/s4_gaussian_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d828bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# flatten the images\n",
    "n_samples = len(X)\n",
    "data = X.reshape((n_samples, -1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y , test_size=0.25, random_state=0)\n",
    "#split to get the train data and test data.\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019ff25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier\n",
    "    models[key].fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = models[key].predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)\n",
    "    precision[key] = precision_score(predictions, y_test)\n",
    "    recall[key] = recall_score(predictions, y_test)\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model\n",
    "#get the accuracy, precision and recall of our binary classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d20ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=create_dataset(r'/home/zw3721/Downloads/2022_master_project/compare images/*.png')\n",
    "\n",
    "n_samples1 = len(Xtest)\n",
    "data1 = Xtest.reshape((n_samples1, -1))\n",
    "\n",
    "print(data1.shape)\n",
    "\n",
    "\n",
    "predictions = models[key].predict(data1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "#use our binary classifiers to do the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2cc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN trained\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=0)\n",
    "model = Sequential()\n",
    "model.add(Reshape((600,600,1), input_shape=(600,600)))\n",
    "model.add(Conv2D(5, 5, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(10, 5, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(20, 5, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(30, 5, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "predictions = model.predict(X_test)\n",
    "#prediction will give the scores and pred give us the good or bad\n",
    "pred = []\n",
    "for i in range (len(predictions)):\n",
    "    if predictions[i]>=np.array(0.9):\n",
    "        x=1 #good\n",
    "    else:\n",
    "        x=0 #bad\n",
    "\n",
    "    pred.append(x)\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "# print(cm)\n",
    "# print(cm[1,0])\n",
    "# print(cm.ravel())\n",
    "\n",
    "TN=cm[0,0]\n",
    "FP=cm[0,1]\n",
    "FN=cm[1,0]\n",
    "TP=cm[1,1]\n",
    "# TN, FP, FN, TP = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "accuracy =  (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "print('Accuracy of the binary classifier = {:0.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10805ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=create_dataset(r'/home/zw3721/Downloads/2022_master_project/compare images/*.png')\n",
    "\n",
    "# n_samples1 = len(Xtest)\n",
    "# data1 = Xtest.reshape((n_samples1, -1))\n",
    "\n",
    "# print(data1.shape)\n",
    "\n",
    "predictions = model.predict(Xtest)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "#use CNN to do the predictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
